{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# ARIMA models\n",
    "with open(\"../../fix/arima_models/1_year_rate_arima_model.pkl\", \"rb\") as f:\n",
    "    one_year_rate_arima_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/arima_models/3_months_rate_arima_model.pkl\", \"rb\") as f:\n",
    "    three_months_rate_arima_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/arima_models/6_months_rate_arima_model.pkl\", \"rb\") as f:\n",
    "    six_months_rate_arima_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/arima_models/10_year_rate_arima_model.pkl\", \"rb\") as f:\n",
    "    ten_year_rate_arima_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/arima_models/CPI_arima_model.pkl\", \"rb\") as f:\n",
    "    cpi_arima_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/arima_models/CSI_index_arima_model.pkl\", \"rb\") as f:\n",
    "    csi_index_arima_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/arima_models/gdp_per_capita_arima_model.pkl\", \"rb\") as f:\n",
    "    gdp_per_capita_arima_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/arima_models/INDPRO_arima_model.pkl\", \"rb\") as f:\n",
    "    indpro_arima_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/arima_models/OECD_CLI_index_arima_model.pkl\", \"rb\") as f:\n",
    "    oecd_cli_index_arima_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/arima_models/PPI_arima_model.pkl\", \"rb\") as f:\n",
    "    ppi_arima_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/arima_models/share_price_arima_model.pkl\", \"rb\") as f:\n",
    "    share_price_arima_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/arima_models/unemployment_rate_arima_model.pkl\", \"rb\") as f:\n",
    "    unemployment_rate_arima_model = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Prophet models\n",
    "with open(\"../../fix/prophet_models/1_year_rate_prophet_model.pkl\", \"rb\") as f:\n",
    "    one_year_rate_prophet_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/prophet_models/3_months_rate_prophet_model.pkl\", \"rb\") as f:\n",
    "    three_months_rate_prophet_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/prophet_models/6_months_rate_prophet_model.pkl\", \"rb\") as f:\n",
    "    six_months_rate_prophet_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/prophet_models/10_year_rate_prophet_model.pkl\", \"rb\") as f:\n",
    "    ten_year_rate_prophet_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/prophet_models/CPI_prophet_model.pkl\", \"rb\") as f:\n",
    "    cpi_prophet_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/prophet_models/CSI_index_prophet_model.pkl\", \"rb\") as f:\n",
    "    csi_index_prophet_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/prophet_models/gdp_per_capita_prophet_model.pkl\", \"rb\") as f:\n",
    "    gdp_per_capita_prophet_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/prophet_models/INDPRO_prophet_model.pkl\", \"rb\") as f:\n",
    "    indpro_prophet_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/prophet_models/OECD_CLI_index_prophet_model.pkl\", \"rb\") as f:\n",
    "    oecd_cli_index_prophet_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/prophet_models/PPI_prophet_model.pkl\", \"rb\") as f:\n",
    "    ppi_prophet_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/prophet_models/share_price_prophet_model.pkl\", \"rb\") as f:\n",
    "    share_price_prophet_model = pickle.load(f)\n",
    "\n",
    "with open(\"../../fix/prophet_models/unemployment_rate_prophet_model.pkl\", \"rb\") as f:\n",
    "    unemployment_rate_prophet_model = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    'CSI_index': csi_index_prophet_model, \n",
    "    '10_year_rate': ten_year_rate_prophet_model, \n",
    "    '3_months_rate': three_months_rate_arima_model, \n",
    "    '1_year_rate': one_year_rate_prophet_model,\n",
    "    'unemployment_rate': unemployment_rate_arima_model, \n",
    "    '6_months_rate': six_months_rate_arima_model, \n",
    "    'PPI': ppi_prophet_model, \n",
    "    'CPI':cpi_prophet_model, \n",
    "    'gdp_per_capita':gdp_per_capita_arima_model, \n",
    "    'OECD_CLI_index': oecd_cli_index_prophet_model, \n",
    "    'INDPRO': indpro_prophet_model, \n",
    "    'share_price':share_price_prophet_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nUSAGE:\\n\\nThis pipeline matches your exact training process:\\n\\n1. Load your models:\\nmodels_dict = {\\n    'CSI_index': csi_index_prophet_model,\\n    '10_year_rate': ten_year_rate_prophet_model,\\n    '3_months_rate': three_months_rate_arima_model,\\n    # ... etc\\n}\\n\\n2. Run production forecasting:\\nproduction_features = production_forecasting_pipeline(\\n    input_data=your_historical_data,  # Should have same features as training\\n    models_dict=models_dict,\\n    forecast_steps=4,\\n    date_col='date',\\n    freq='M'\\n)\\n\\n3. The output will have exactly your 18 required features for recession prediction\\n\\nKEY DIFFERENCES FROM PREVIOUS ATTEMPTS:\\n- Matches your training's exogenous variable preparation exactly\\n- Uses iterative forecasting (ARIMA first, then Prophet with ARIMA results)\\n- Handles regressor preparation the same way as your training code\\n- Applies STL decomposition with same parameters as training\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def production_forecasting_pipeline(input_data, models_dict, forecast_steps, date_col='date', freq='M'):\n",
    "    \"\"\"\n",
    "    Production forecasting pipeline that matches your training process\n",
    "    \n",
    "    Key insight: Your models were trained with specific feature sets:\n",
    "    - ARIMA models: Use ALL features except recession targets as exogenous variables\n",
    "    - Prophet models: Use ALL features except recession targets as regressors\n",
    "    \n",
    "    Strategy: Use iterative forecasting approach similar to your training\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Production Forecasting Pipeline - {forecast_steps} steps ahead\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Recession targets to exclude (from your training code)\n",
    "    recession_targets = [\n",
    "        'recession_probability', '1_month_recession_probability',\n",
    "        '3_month_recession_probability', '6_month_recession_probability'\n",
    "    ]\n",
    "    \n",
    "    # Financial indicators (your target variables)\n",
    "    financial_indicators = [\n",
    "        '1_year_rate', '3_months_rate', '6_months_rate', 'CPI', 'INDPRO',\n",
    "        '10_year_rate', 'share_price', 'unemployment_rate', 'PPI',\n",
    "        'OECD_CLI_index', 'CSI_index', 'gdp_per_capita'\n",
    "    ]\n",
    "    \n",
    "    # 1. Create future date range\n",
    "    if date_col in input_data.columns:\n",
    "        last_date = pd.to_datetime(input_data[date_col].max())\n",
    "        if freq == 'M':\n",
    "            future_dates = pd.date_range(start=last_date + pd.DateOffset(months=1), \n",
    "                                       periods=forecast_steps, freq='M')\n",
    "        elif freq == 'Q':\n",
    "            future_dates = pd.date_range(start=last_date + pd.DateOffset(months=3), \n",
    "                                       periods=forecast_steps, freq='Q')\n",
    "        else:\n",
    "            future_dates = pd.date_range(start=last_date + pd.Timedelta(days=30), \n",
    "                                       periods=forecast_steps, freq='M')\n",
    "        \n",
    "        result_data = pd.DataFrame({date_col: future_dates})\n",
    "    else:\n",
    "        result_data = pd.DataFrame(index=range(forecast_steps))\n",
    "    \n",
    "    # 2. Separate models by type\n",
    "    arima_models = {}\n",
    "    prophet_models = {}\n",
    "    \n",
    "    for indicator, model in models_dict.items():\n",
    "        model_type = str(type(model)).lower()\n",
    "        if 'arima' in model_type:\n",
    "            arima_models[indicator] = model\n",
    "        elif 'prophet' in model_type:\n",
    "            prophet_models[indicator] = model\n",
    "        else:\n",
    "            arima_models[indicator] = model  # Default to ARIMA treatment\n",
    "    \n",
    "    print(f\"ARIMA models: {list(arima_models.keys())}\")\n",
    "    print(f\"Prophet models: {list(prophet_models.keys())}\")\n",
    "    \n",
    "    # 3. Forecast ARIMA models first (they need exogenous variables)\n",
    "    print(f\"\\nStep 1: Forecasting ARIMA models...\")\n",
    "    \n",
    "    for indicator, model in arima_models.items():\n",
    "        try:\n",
    "            print(f\"  Processing ARIMA: {indicator}...\")\n",
    "            \n",
    "            # Prepare exogenous variables for ARIMA (same as training)\n",
    "            features_to_exclude = [date_col] + recession_targets + [indicator]\n",
    "            available_features = [c for c in input_data.columns if c not in features_to_exclude]\n",
    "            \n",
    "            print(f\"    Available exog features: {len(available_features)}\")\n",
    "            \n",
    "            if len(available_features) == 0:\n",
    "                # No exogenous variables - simple ARIMA\n",
    "                predictions = model.forecast(steps=forecast_steps)\n",
    "                if hasattr(predictions, 'values'):\n",
    "                    predictions = predictions.values\n",
    "            else:\n",
    "                # ARIMA with exogenous variables\n",
    "                exog_data = input_data[available_features].copy()\n",
    "                \n",
    "                # Clean exogenous data (same as your training)\n",
    "                exog_data = exog_data.fillna(method='ffill').fillna(method='bfill')\n",
    "                exog_data = exog_data.replace([np.inf, -np.inf], np.nan).fillna(method='ffill').fillna(method='bfill')\n",
    "                \n",
    "                # Remove non-varying columns\n",
    "                varying_cols = [c for c in exog_data.columns if exog_data[c].nunique() > 1]\n",
    "                exog_data = exog_data[varying_cols]\n",
    "                \n",
    "                print(f\"    Using {len(varying_cols)} exog variables\")\n",
    "                \n",
    "                if len(varying_cols) == 0:\n",
    "                    # No varying exogenous variables\n",
    "                    predictions = model.forecast(steps=forecast_steps)\n",
    "                else:\n",
    "                    # Create future exogenous variables (forward fill last values)\n",
    "                    last_exog_values = exog_data.iloc[-1:].copy()\n",
    "                    future_exog = pd.concat([last_exog_values] * forecast_steps, ignore_index=True)\n",
    "                    \n",
    "                    # Check if model expects more exogenous variables than we have\n",
    "                    expected_exog_count = getattr(model.model, 'k_exog', 0)\n",
    "                    \n",
    "                    if expected_exog_count > 0 and len(varying_cols) != expected_exog_count:\n",
    "                        print(f\"    Warning: Model expects {expected_exog_count} exog vars, but have {len(varying_cols)}\")\n",
    "                        \n",
    "                        if len(varying_cols) < expected_exog_count:\n",
    "                            # Pad with zeros to match expected shape\n",
    "                            missing_cols = expected_exog_count - len(varying_cols)\n",
    "                            for i in range(missing_cols):\n",
    "                                future_exog[f'missing_exog_{i}'] = 0.0\n",
    "                            print(f\"    Padded with {missing_cols} zero columns\")\n",
    "                        else:\n",
    "                            # Take only the first expected_exog_count columns\n",
    "                            future_exog = future_exog.iloc[:, :expected_exog_count]\n",
    "                            print(f\"    Truncated to {expected_exog_count} columns\")\n",
    "                    \n",
    "                    # Make forecast with exogenous variables\n",
    "                    predictions = model.forecast(steps=forecast_steps, exog=future_exog)\n",
    "                \n",
    "                if hasattr(predictions, 'values'):\n",
    "                    predictions = predictions.values\n",
    "            \n",
    "            # Ensure correct length\n",
    "            if len(predictions) != forecast_steps:\n",
    "                if len(predictions) > forecast_steps:\n",
    "                    predictions = predictions[:forecast_steps]\n",
    "                else:\n",
    "                    last_val = predictions[-1] if len(predictions) > 0 else 0\n",
    "                    predictions = list(predictions) + [last_val] * (forecast_steps - len(predictions))\n",
    "            \n",
    "            result_data[indicator] = predictions\n",
    "            print(f\"    ✓ ARIMA forecast: {indicator} ({len(predictions)} values)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    ✗ ARIMA failed for {indicator}: {str(e)}\")\n",
    "            # Use trend-based fallback\n",
    "            predictions = trend_based_forecast(input_data, indicator, forecast_steps)\n",
    "            result_data[indicator] = predictions\n",
    "            print(f\"    ✓ Fallback forecast: {indicator}\")\n",
    "    \n",
    "    # 4. Now forecast Prophet models (they need ALL features as regressors)\n",
    "    print(f\"\\nStep 2: Forecasting Prophet models...\")\n",
    "    \n",
    "    for indicator, model in prophet_models.items():\n",
    "        try:\n",
    "            print(f\"  Processing Prophet: {indicator}...\")\n",
    "            \n",
    "            # Create future dataframe for Prophet\n",
    "            future_df = model.make_future_dataframe(periods=forecast_steps, freq=freq)\n",
    "            \n",
    "            # Get regressor names from the model\n",
    "            regressors = []\n",
    "            if hasattr(model, 'extra_regressors'):\n",
    "                regressors = list(model.extra_regressors.keys())\n",
    "            \n",
    "            print(f\"    Model needs {len(regressors)} regressors\")\n",
    "            print(f\"    Sample regressors: {regressors[:5]}...\" if len(regressors) > 5 else f\"    Regressors: {regressors}\")\n",
    "            \n",
    "            # Prepare regressor values for the entire future_df\n",
    "            historical_length = len(future_df) - forecast_steps\n",
    "            \n",
    "            for regressor in regressors:\n",
    "                try:\n",
    "                    if regressor in result_data.columns:\n",
    "                        # Use ARIMA predictions for this regressor\n",
    "                        if regressor in input_data.columns:\n",
    "                            hist_values = input_data[regressor].fillna(method='ffill').fillna(method='bfill').tolist()\n",
    "                        else:\n",
    "                            hist_values = [0.0] * historical_length\n",
    "                        \n",
    "                        future_values = result_data[regressor].tolist()\n",
    "                        all_values = hist_values + future_values\n",
    "                        \n",
    "                        # Adjust length to match future_df\n",
    "                        if len(all_values) > len(future_df):\n",
    "                            all_values = all_values[:len(future_df)]\n",
    "                        elif len(all_values) < len(future_df):\n",
    "                            last_val = all_values[-1] if all_values else 0\n",
    "                            all_values.extend([last_val] * (len(future_df) - len(all_values)))\n",
    "                        \n",
    "                        future_df[regressor] = all_values\n",
    "                        \n",
    "                    elif regressor in input_data.columns:\n",
    "                        # Use historical data + forward fill\n",
    "                        hist_values = input_data[regressor].fillna(method='ffill').fillna(method='bfill').tolist()\n",
    "                        \n",
    "                        # Forward fill for future\n",
    "                        last_val = hist_values[-1] if hist_values else 0\n",
    "                        future_values = [last_val] * forecast_steps\n",
    "                        all_values = hist_values + future_values\n",
    "                        \n",
    "                        # Adjust length\n",
    "                        if len(all_values) > len(future_df):\n",
    "                            all_values = all_values[:len(future_df)]\n",
    "                        elif len(all_values) < len(future_df):\n",
    "                            last_val = all_values[-1] if all_values else 0\n",
    "                            all_values.extend([last_val] * (len(future_df) - len(all_values)))\n",
    "                        \n",
    "                        future_df[regressor] = all_values\n",
    "                        \n",
    "                    else:\n",
    "                        # Missing regressor - use zeros\n",
    "                        future_df[regressor] = [0.0] * len(future_df)\n",
    "                        \n",
    "                except Exception as reg_error:\n",
    "                    print(f\"      Warning: Error with regressor {regressor}: {str(reg_error)}\")\n",
    "                    future_df[regressor] = [0.0] * len(future_df)\n",
    "            \n",
    "            # Make Prophet prediction\n",
    "            forecast_result = model.predict(future_df)\n",
    "            predictions = forecast_result['yhat'].tail(forecast_steps).values\n",
    "            \n",
    "            result_data[indicator] = predictions\n",
    "            print(f\"    ✓ Prophet forecast: {indicator} ({len(predictions)} values)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    ✗ Prophet failed for {indicator}: {str(e)}\")\n",
    "            # Use trend-based fallback\n",
    "            predictions = trend_based_forecast(input_data, indicator, forecast_steps)\n",
    "            result_data[indicator] = predictions\n",
    "            print(f\"    ✓ Fallback forecast: {indicator}\")\n",
    "    \n",
    "    # 5. Apply STL decomposition (same as your training)\n",
    "    print(f\"\\nStep 3: Applying STL decomposition...\")\n",
    "    \n",
    "    indicators = list(models_dict.keys())\n",
    "    for indicator in indicators:\n",
    "        if indicator in result_data.columns:\n",
    "            try:\n",
    "                series = pd.Series(result_data[indicator])\n",
    "                \n",
    "                # Combine with historical data for better STL\n",
    "                if indicator in input_data.columns:\n",
    "                    historical_series = input_data[indicator].fillna(method='ffill').fillna(method='bfill')\n",
    "                    combined_series = pd.concat([historical_series, series], ignore_index=True)\n",
    "                else:\n",
    "                    combined_series = series\n",
    "                \n",
    "                if len(combined_series.dropna()) >= 24:\n",
    "                    # Use STL with same parameters as your training\n",
    "                    stl = STL(combined_series, seasonal=13, period=12)\n",
    "                    decomposition = stl.fit()\n",
    "                    \n",
    "                    # Extract forecast portion\n",
    "                    trend = decomposition.trend.iloc[-forecast_steps:].values\n",
    "                    residual = decomposition.resid.iloc[-forecast_steps:].values\n",
    "                    \n",
    "                    result_data[f'{indicator}_trend'] = trend\n",
    "                    result_data[f'{indicator}_residual'] = residual\n",
    "                else:\n",
    "                    # Short series fallback\n",
    "                    mean_val = series.mean()\n",
    "                    result_data[f'{indicator}_trend'] = [mean_val] * forecast_steps\n",
    "                    result_data[f'{indicator}_residual'] = (series - mean_val).values\n",
    "                \n",
    "                print(f\"  ✓ STL: {indicator}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ STL failed for {indicator}: {str(e)}\")\n",
    "                # Simple fallback\n",
    "                result_data[f'{indicator}_trend'] = result_data[indicator].values\n",
    "                result_data[f'{indicator}_residual'] = [0.0] * forecast_steps\n",
    "    \n",
    "    # 6. Extract required features AND financial indicators\n",
    "    required_features = [\n",
    "        'CSI_index_trend', '10_year_rate_trend', '3_months_rate_trend', \n",
    "        '1_year_rate_trend', 'unemployment_rate_trend', '6_months_rate_trend',\n",
    "        'PPI_trend', 'CPI_trend', 'gdp_per_capita_trend', 'gdp_per_capita_residual',\n",
    "        'OECD_CLI_index_trend', 'OECD_CLI_index_residual', '3_months_rate_residual',\n",
    "        'INDPRO_trend', 'share_price_trend', '6_months_rate_residual',\n",
    "        '1_year_rate_residual', '10_year_rate_residual'\n",
    "    ]\n",
    "    \n",
    "    # Financial indicators (raw predictions)\n",
    "    financial_indicators = [\n",
    "        '1_year_rate', '3_months_rate', '6_months_rate', 'CPI', 'INDPRO',\n",
    "        '10_year_rate', 'share_price', 'unemployment_rate', 'PPI',\n",
    "        'OECD_CLI_index', 'CSI_index', 'gdp_per_capita'\n",
    "    ]\n",
    "    \n",
    "    # Combine date + financial indicators + required features\n",
    "    all_output_columns = [date_col] + financial_indicators + required_features\n",
    "    \n",
    "    # Keep available columns from result_data\n",
    "    final_columns = [col for col in all_output_columns if col in result_data.columns]\n",
    "    final_data = result_data[final_columns].copy()\n",
    "    \n",
    "    # Fill missing financial indicators with 0\n",
    "    for indicator in financial_indicators:\n",
    "        if indicator not in final_data.columns:\n",
    "            final_data[indicator] = [0.0] * forecast_steps\n",
    "    \n",
    "    # Fill missing features with 0\n",
    "    for feature in required_features:\n",
    "        if feature not in final_data.columns:\n",
    "            final_data[feature] = [0.0] * forecast_steps\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"PRODUCTION FORECASTING COMPLETE\")\n",
    "    print(f\"=\"*60)\n",
    "    print(f\"Final shape: {final_data.shape}\")\n",
    "    if date_col in final_data.columns:\n",
    "        print(f\"Forecast period: {final_data[date_col].min()} to {final_data[date_col].max()}\")\n",
    "    print(f\"Generated {len(financial_indicators)} financial indicators + {len(required_features)} engineered features\")\n",
    "    print(f\"Financial indicators: {financial_indicators}\")\n",
    "    print(f\"Sample features: {required_features[:5]}...\")\n",
    "    \n",
    "    return final_data\n",
    "\n",
    "def trend_based_forecast(input_data, indicator, forecast_steps):\n",
    "    \"\"\"\n",
    "    Trend-based forecasting fallback (matches your training approach)\n",
    "    \"\"\"\n",
    "    if indicator not in input_data.columns or input_data[indicator].isna().all():\n",
    "        return [0.0] * forecast_steps\n",
    "    \n",
    "    series = input_data[indicator].fillna(method='ffill').fillna(method='bfill').dropna()\n",
    "    \n",
    "    if len(series) < 3:\n",
    "        return [series.iloc[-1] if len(series) > 0 else 0.0] * forecast_steps\n",
    "    \n",
    "    # Simple linear trend\n",
    "    x = np.arange(len(series))\n",
    "    y = series.values\n",
    "    \n",
    "    try:\n",
    "        slope, intercept = np.polyfit(x, y, 1)\n",
    "        last_index = len(series) - 1\n",
    "        \n",
    "        predictions = []\n",
    "        for step in range(1, forecast_steps + 1):\n",
    "            pred = slope * (last_index + step) + intercept\n",
    "            predictions.append(pred)\n",
    "        \n",
    "        return predictions\n",
    "        \n",
    "    except:\n",
    "        # Ultimate fallback - last value\n",
    "        return [series.iloc[-1]] * forecast_steps\n",
    "\n",
    "\"\"\"\n",
    "USAGE:\n",
    "\n",
    "This pipeline matches your exact training process:\n",
    "\n",
    "1. Load your models:\n",
    "models_dict = {\n",
    "    'CSI_index': csi_index_prophet_model,\n",
    "    '10_year_rate': ten_year_rate_prophet_model,\n",
    "    '3_months_rate': three_months_rate_arima_model,\n",
    "    # ... etc\n",
    "}\n",
    "\n",
    "2. Run production forecasting:\n",
    "production_features = production_forecasting_pipeline(\n",
    "    input_data=your_historical_data,  # Should have same features as training\n",
    "    models_dict=models_dict,\n",
    "    forecast_steps=4,\n",
    "    date_col='date',\n",
    "    freq='M'\n",
    ")\n",
    "\n",
    "3. The output will have exactly your 18 required features for recession prediction\n",
    "\n",
    "KEY DIFFERENCES FROM PREVIOUS ATTEMPTS:\n",
    "- Matches your training's exogenous variable preparation exactly\n",
    "- Uses iterative forecasting (ARIMA first, then Prophet with ARIMA results)\n",
    "- Handles regressor preparation the same way as your training code\n",
    "- Applies STL decomposition with same parameters as training\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data = pd.read_csv('../../data/fix/feature_selected_recession_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production Forecasting Pipeline - 4 steps ahead\n",
      "============================================================\n",
      "ARIMA models: ['3_months_rate', 'unemployment_rate', '6_months_rate', 'gdp_per_capita']\n",
      "Prophet models: ['CSI_index', '10_year_rate', '1_year_rate', 'PPI', 'CPI', 'OECD_CLI_index', 'INDPRO', 'share_price']\n",
      "\n",
      "Step 1: Forecasting ARIMA models...\n",
      "  Processing ARIMA: 3_months_rate...\n",
      "    Available exog features: 29\n",
      "    Using 17 exog variables\n",
      "    Warning: Model expects 29 exog vars, but have 17\n",
      "    Padded with 12 zero columns\n",
      "    ✓ ARIMA forecast: 3_months_rate (4 values)\n",
      "  Processing ARIMA: unemployment_rate...\n",
      "    Available exog features: 29\n",
      "    Using 17 exog variables\n",
      "    Warning: Model expects 29 exog vars, but have 17\n",
      "    Padded with 12 zero columns\n",
      "    ✓ ARIMA forecast: unemployment_rate (4 values)\n",
      "  Processing ARIMA: 6_months_rate...\n",
      "    Available exog features: 29\n",
      "    Using 17 exog variables\n",
      "    Warning: Model expects 29 exog vars, but have 17\n",
      "    Padded with 12 zero columns\n",
      "    ✓ ARIMA forecast: 6_months_rate (4 values)\n",
      "  Processing ARIMA: gdp_per_capita...\n",
      "    Available exog features: 29\n",
      "    Using 17 exog variables\n",
      "    Warning: Model expects 29 exog vars, but have 17\n",
      "    Padded with 12 zero columns\n",
      "    ✓ ARIMA forecast: gdp_per_capita (4 values)\n",
      "\n",
      "Step 2: Forecasting Prophet models...\n",
      "  Processing Prophet: CSI_index...\n",
      "    Model needs 29 regressors\n",
      "    Sample regressors: ['1_year_rate', '3_months_rate', '6_months_rate', 'CPI', 'INDPRO']...\n",
      "    ✓ Prophet forecast: CSI_index (4 values)\n",
      "  Processing Prophet: 10_year_rate...\n",
      "    Model needs 29 regressors\n",
      "    Sample regressors: ['1_year_rate', '3_months_rate', '6_months_rate', 'CPI', 'INDPRO']...\n",
      "    ✓ Prophet forecast: 10_year_rate (4 values)\n",
      "  Processing Prophet: 1_year_rate...\n",
      "    Model needs 29 regressors\n",
      "    Sample regressors: ['3_months_rate', '6_months_rate', 'CPI', 'INDPRO', '10_year_rate']...\n",
      "    ✓ Prophet forecast: 1_year_rate (4 values)\n",
      "  Processing Prophet: PPI...\n",
      "    Model needs 29 regressors\n",
      "    Sample regressors: ['1_year_rate', '3_months_rate', '6_months_rate', 'CPI', 'INDPRO']...\n",
      "    ✓ Prophet forecast: PPI (4 values)\n",
      "  Processing Prophet: CPI...\n",
      "    Model needs 29 regressors\n",
      "    Sample regressors: ['1_year_rate', '3_months_rate', '6_months_rate', 'INDPRO', '10_year_rate']...\n",
      "    ✓ Prophet forecast: CPI (4 values)\n",
      "  Processing Prophet: OECD_CLI_index...\n",
      "    Model needs 29 regressors\n",
      "    Sample regressors: ['1_year_rate', '3_months_rate', '6_months_rate', 'CPI', 'INDPRO']...\n",
      "    ✓ Prophet forecast: OECD_CLI_index (4 values)\n",
      "  Processing Prophet: INDPRO...\n",
      "    Model needs 29 regressors\n",
      "    Sample regressors: ['1_year_rate', '3_months_rate', '6_months_rate', 'CPI', '10_year_rate']...\n",
      "    ✓ Prophet forecast: INDPRO (4 values)\n",
      "  Processing Prophet: share_price...\n",
      "    Model needs 29 regressors\n",
      "    Sample regressors: ['1_year_rate', '3_months_rate', '6_months_rate', 'CPI', 'INDPRO']...\n",
      "    ✓ Prophet forecast: share_price (4 values)\n",
      "\n",
      "Step 3: Applying STL decomposition...\n",
      "  ✓ STL: CSI_index\n",
      "  ✓ STL: 10_year_rate\n",
      "  ✓ STL: 3_months_rate\n",
      "  ✓ STL: 1_year_rate\n",
      "  ✓ STL: unemployment_rate\n",
      "  ✓ STL: 6_months_rate\n",
      "  ✓ STL: PPI\n",
      "  ✓ STL: CPI\n",
      "  ✓ STL: gdp_per_capita\n",
      "  ✓ STL: OECD_CLI_index\n",
      "  ✓ STL: INDPRO\n",
      "  ✓ STL: share_price\n",
      "\n",
      "============================================================\n",
      "PRODUCTION FORECASTING COMPLETE\n",
      "============================================================\n",
      "Final shape: (4, 31)\n",
      "Forecast period: 2025-06-30 00:00:00 to 2025-09-30 00:00:00\n",
      "Generated 12 financial indicators + 18 engineered features\n",
      "Financial indicators: ['1_year_rate', '3_months_rate', '6_months_rate', 'CPI', 'INDPRO', '10_year_rate', 'share_price', 'unemployment_rate', 'PPI', 'OECD_CLI_index', 'CSI_index', 'gdp_per_capita']\n",
      "Sample features: ['CSI_index_trend', '10_year_rate_trend', '3_months_rate_trend', '1_year_rate_trend', 'unemployment_rate_trend']...\n"
     ]
    }
   ],
   "source": [
    "# Use the fixed function\n",
    "production_features = production_forecasting_pipeline(\n",
    "    input_data=historical_data,\n",
    "    models_dict=models_dict,\n",
    "    forecast_steps=4,\n",
    "    date_col='date',\n",
    "    freq='M'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', '1_year_rate', '3_months_rate', '6_months_rate', 'CPI',\n",
       "       'INDPRO', '10_year_rate', 'share_price', 'unemployment_rate', 'PPI',\n",
       "       'OECD_CLI_index', 'CSI_index', 'gdp_per_capita', 'CSI_index_trend',\n",
       "       '10_year_rate_trend', '3_months_rate_trend', '1_year_rate_trend',\n",
       "       'unemployment_rate_trend', '6_months_rate_trend', 'PPI_trend',\n",
       "       'CPI_trend', 'gdp_per_capita_trend', 'gdp_per_capita_residual',\n",
       "       'OECD_CLI_index_trend', 'OECD_CLI_index_residual',\n",
       "       '3_months_rate_residual', 'INDPRO_trend', 'share_price_trend',\n",
       "       '6_months_rate_residual', '1_year_rate_residual',\n",
       "       '10_year_rate_residual'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "production_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
