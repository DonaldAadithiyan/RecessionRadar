{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ---------- Configuration ----------\n",
    "financial_indicators = [\n",
    "    '1_year_rate', '3_months_rate', '6_months_rate', 'CPI', 'INDPRO',\n",
    "    '10_year_rate', 'share_price', 'unemployment_rate', 'PPI',\n",
    "    'OECD_CLI_index', 'CSI_index', 'gdp_per_capita'\n",
    "]\n",
    "\n",
    "recession_targets = [\n",
    "    'recession_probability', '1_month_recession_probability',\n",
    "    '3_month_recession_probability', '6_month_recession_probability'\n",
    "]\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "\n",
    "def check_stationarity(series):\n",
    "    result = adfuller(series.dropna())\n",
    "    return result[1] < 0.05\n",
    "\n",
    "def make_stationary(series, max_diff=2):\n",
    "    original_series = series.copy()\n",
    "    diff_order = 0\n",
    "    for d in range(max_diff + 1):\n",
    "        if d == 0:\n",
    "            current_series = series\n",
    "        else:\n",
    "            current_series = current_series.diff().dropna()\n",
    "            diff_order = d\n",
    "        if len(current_series) < 20:\n",
    "            break\n",
    "        if adfuller(current_series.dropna())[1] < 0.05:\n",
    "            break\n",
    "    return current_series, diff_order\n",
    "\n",
    "def prepare_varmax_data(train_df, test_df, target_indicators, max_exog_features=10):\n",
    "    features_to_exclude = ['date'] + recession_targets + target_indicators\n",
    "    available_exog = [c for c in train_df.columns if c not in features_to_exclude]\n",
    "    \n",
    "    if len(available_exog) > max_exog_features:\n",
    "        correlations = {}\n",
    "        for feature in available_exog:\n",
    "            corr_sum = sum(\n",
    "                abs(train_df[feature].corr(train_df[t])) if not np.isnan(train_df[feature].corr(train_df[t])) else 0\n",
    "                for t in target_indicators\n",
    "            )\n",
    "            correlations[feature] = corr_sum\n",
    "        available_exog = [f[0] for f in sorted(correlations.items(), key=lambda x: x[1], reverse=True)[:max_exog_features]]\n",
    "    \n",
    "    # Prepare targets and exog\n",
    "    train_targets = train_df[['date'] + target_indicators].set_index('date')\n",
    "    test_targets = test_df[['date'] + target_indicators].set_index('date')\n",
    "    train_exog = train_df[['date'] + available_exog].set_index('date')\n",
    "    test_exog = test_df[['date'] + available_exog].set_index('date')\n",
    "    \n",
    "    # Fill missing values\n",
    "    for df in [train_targets, test_targets, train_exog, test_exog]:\n",
    "        df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        df.fillna(method='ffill', inplace=True)\n",
    "        df.fillna(method='bfill', inplace=True)\n",
    "        for col in df.columns:\n",
    "            if df[col].isnull().any():\n",
    "                df[col].fillna(df[col].median(), inplace=True)\n",
    "    \n",
    "    return train_targets, test_targets, train_exog, test_exog, available_exog\n",
    "\n",
    "def check_and_make_stationary(data):\n",
    "    stationary_data = data.copy()\n",
    "    diff_orders = {}\n",
    "    for col in data.columns:\n",
    "        series, diff_order = make_stationary(data[col])\n",
    "        stationary_data[col] = np.nan\n",
    "        stationary_data.loc[series.index, col] = series\n",
    "        diff_orders[col] = diff_order\n",
    "    stationary_data = stationary_data.dropna()\n",
    "    return stationary_data, diff_orders\n",
    "\n",
    "def make_varmax_objective(train_targets, train_exog, val_targets, val_exog):\n",
    "    def objective(trial):\n",
    "        order = (trial.suggest_int('p', 1, 4), trial.suggest_int('q', 0, 2))\n",
    "        trend = trial.suggest_categorical('trend', ['n', 'c', 't', 'ct'])\n",
    "        try:\n",
    "            model = VARMAX(\n",
    "                endog=train_targets,\n",
    "                exog=train_exog,\n",
    "                order=order,\n",
    "                trend=trend,\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False\n",
    "            )\n",
    "            fitted = model.fit(disp=False, maxiter=100, method='lbfgs')\n",
    "            forecast = fitted.forecast(steps=len(val_targets), exog=val_exog.values)\n",
    "            rmse_sum = sum(np.sqrt(mean_squared_error(val_targets[col], forecast[:, i]))\n",
    "                           for i, col in enumerate(val_targets.columns))\n",
    "            return rmse_sum / len(val_targets.columns)\n",
    "        except Exception:\n",
    "            return float('inf')\n",
    "    return objective\n",
    "\n",
    "def fit_varmax_model(train_targets, test_targets, train_exog, test_exog, n_trials=20):\n",
    "    val_size = min(12, len(test_targets), len(train_targets)//4)\n",
    "    train_fit, train_exog_fit = train_targets.iloc[:-val_size], train_exog.iloc[:-val_size]\n",
    "    val_targets, val_exog = train_targets.iloc[-val_size:], train_exog.iloc[-val_size:]\n",
    "    \n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(make_varmax_objective(train_fit, train_exog_fit, val_targets, val_exog), n_trials=n_trials)\n",
    "    best_order = (study.best_params['p'], study.best_params['q'])\n",
    "    best_trend = study.best_params['trend']\n",
    "    \n",
    "    final_model = VARMAX(endog=train_targets, exog=train_exog, order=best_order, trend=best_trend,\n",
    "                         enforce_stationarity=False, enforce_invertibility=False)\n",
    "    fitted_model = final_model.fit(disp=False, maxiter=200, method='lbfgs')\n",
    "    \n",
    "    forecast = fitted_model.forecast(steps=len(test_targets), exog=test_exog.values)\n",
    "    \n",
    "    results = {}\n",
    "    for i, col in enumerate(train_targets.columns):\n",
    "        y_true = test_targets[col].values\n",
    "        y_pred = forecast[:, i]\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        mask = y_true != 0\n",
    "        mape = np.mean(np.abs((y_true[mask]-y_pred[mask])/y_true[mask]))*100 if mask.any() else np.inf\n",
    "        results[col] = {'forecast': y_pred, 'actual': y_true, 'mae': mae, 'rmse': rmse, 'mape': mape}\n",
    "    return fitted_model, results\n",
    "\n",
    "def invert_differencing(forecast_df, last_train_values, diff_orders):\n",
    "    inv_df = forecast_df.copy()\n",
    "    for col in forecast_df.columns:\n",
    "        d = diff_orders.get(col, 0)\n",
    "        if d > 0:\n",
    "            prev_value = last_train_values[col]\n",
    "            for _ in range(d):\n",
    "                inv_series = inv_df[col].cumsum() + prev_value\n",
    "                inv_df[col] = inv_series\n",
    "                prev_value = inv_series.iloc[-1]\n",
    "    return inv_df\n",
    "\n",
    "# ---------- Main Pipeline ----------\n",
    "def run_varmax_pipeline(train_df, test_df, target_indicators=None, max_exog_features=10,\n",
    "                        n_trials=20, save_model=True, save_plots=True):\n",
    "    \n",
    "    if target_indicators is None:\n",
    "        target_indicators = ['CPI', 'unemployment_rate', '1_year_rate', 'share_price', 'INDPRO']\n",
    "    \n",
    "    train_targets, test_targets, train_exog, test_exog, exog_features = prepare_varmax_data(\n",
    "        train_df, test_df, target_indicators, max_exog_features\n",
    "    )\n",
    "    \n",
    "    train_targets_stat, target_diff_orders = check_and_make_stationary(train_targets)\n",
    "    train_exog_stat, exog_diff_orders = check_and_make_stationary(train_exog)\n",
    "    \n",
    "    # Align test data by applying same differencing\n",
    "    test_targets_stat = test_targets.copy()\n",
    "    test_exog_stat = test_exog.copy()\n",
    "    for col, d in target_diff_orders.items():\n",
    "        for _ in range(d):\n",
    "            test_targets_stat[col] = test_targets_stat[col].diff()\n",
    "    for col, d in exog_diff_orders.items():\n",
    "        for _ in range(d):\n",
    "            test_exog_stat[col] = test_exog_stat[col].diff()\n",
    "    test_targets_stat.dropna(inplace=True)\n",
    "    test_exog_stat.dropna(inplace=True)\n",
    "    \n",
    "    model, results = fit_varmax_model(train_targets_stat, test_targets_stat, train_exog_stat, test_exog_stat, n_trials)\n",
    "    \n",
    "    # Invert differencing for original scale\n",
    "    last_train_values = train_targets.iloc[-1]\n",
    "    forecast_df = pd.DataFrame({col: results[col]['forecast'] for col in target_indicators})\n",
    "    forecast_orig = invert_differencing(forecast_df, last_train_values, target_diff_orders)\n",
    "    \n",
    "    # Save model\n",
    "    if save_model:\n",
    "        os.makedirs('varmax_models', exist_ok=True)\n",
    "        with open('varmax_models/varmax_model.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        print(\"Saved model: varmax_models/varmax_model.pkl\")\n",
    "    \n",
    "    # Plot results\n",
    "    os.makedirs('varmax_plots', exist_ok=True)\n",
    "    for col in target_indicators:\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.plot(test_targets.index, results[col]['actual'], label='Actual', color='green')\n",
    "        plt.plot(test_targets.index, forecast_orig[col], label='Forecast', color='red')\n",
    "        plt.title(f\"{col} Forecast\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        if save_plots:\n",
    "            plt.savefig(f'varmax_plots/{col}_forecast.png')\n",
    "            print(f\"Saved plot: varmax_plots/{col}_forecast.png\")\n",
    "        plt.show()\n",
    "    \n",
    "    return model, results, forecast_orig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/fix/feature_selected_recession_train.csv')\n",
    "test_df = pd.read_csv('../data/fix/feature_selected_recession_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-12 10:42:05,022] A new study created in memory with name: no-name-ca95a2cd-2fb7-4ba0-aac6-66c5b192f6ee\n",
      "[W 2025-10-12 17:04:46,027] Trial 0 failed with parameters: {'p': 2, 'q': 0, 'trend': 't'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/donaldaadithiyan/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/vx/lz_s92194473v0lcw_034qq40000gn/T/ipykernel_67672/1264124305.py\", line 101, in objective\n",
      "    fitted = model.fit(disp=False, maxiter=100, method='lbfgs')\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/donaldaadithiyan/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/statsmodels/tsa/statespace/mlemodel.py\", line 704, in fit\n",
      "    mlefit = super(MLEModel, self).fit(start_params, method=method,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/donaldaadithiyan/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/statsmodels/base/model.py\", line 566, in fit\n",
      "    xopt, retvals, optim_settings = optimizer._fit(f, score, start_params,\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/donaldaadithiyan/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/statsmodels/base/optimizer.py\", line 242, in _fit\n",
      "    xopt, retvals = func(objective, gradient, start_params, fargs, kwargs,\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/donaldaadithiyan/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/statsmodels/base/optimizer.py\", line 659, in _fit_lbfgs\n",
      "    retvals = optimize.fmin_l_bfgs_b(func, start_params, maxiter=maxiter,\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/donaldaadithiyan/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/scipy/optimize/_lbfgsb_py.py\", line 199, in fmin_l_bfgs_b\n",
      "    res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/donaldaadithiyan/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/donaldaadithiyan/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/donaldaadithiyan/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py\", line 177, in __init__\n",
      "    self._update_grad()\n",
      "  File \"/Users/donaldaadithiyan/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py\", line 256, in _update_grad\n",
      "    self._update_grad_impl()\n",
      "  File \"/Users/donaldaadithiyan/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py\", line 173, in update_grad\n",
      "    self.g = approx_derivative(fun_wrapped, self.x, f0=self.f,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/donaldaadithiyan/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/scipy/optimize/_numdiff.py\", line 505, in approx_derivative\n",
      "    return _dense_difference(fun_wrapped, x0, f0, h,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/donaldaadithiyan/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/scipy/optimize/_numdiff.py\", line 576, in _dense_difference\n",
      "    df = fun(x) - f0\n",
      "         ^^^^^^\n",
      "  File \"/Users/donaldaadithiyan/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/scipy/optimize/_numdiff.py\", line 456, in fun_wrapped\n",
      "    f = np.atleast_1d(fun(x, *args, **kwargs))\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/donaldaadithiyan/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/donaldaadithiyan/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/statsmodels/base/model.py\", line 534, in f\n",
      "    return -self.loglike(params, *args) / nobs\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/donaldaadithiyan/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/statsmodels/tsa/statespace/mlemodel.py\", line 939, in loglike\n",
      "    loglike = self.ssm.loglike(complex_step=complex_step, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/donaldaadithiyan/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/statsmodels/tsa/statespace/kalman_filter.py\", line 1001, in loglike\n",
      "    kfilter = self._filter(**kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/donaldaadithiyan/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/statsmodels/tsa/statespace/kalman_filter.py\", line 924, in _filter\n",
      "    kfilter()\n",
      "KeyboardInterrupt\n",
      "[W 2025-10-12 17:04:46,035] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      2\u001b[39m financial_indicators = [\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m1_year_rate\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m3_months_rate\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m6_months_rate\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mCPI\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mINDPRO\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m10_year_rate\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mshare_price\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33munemployment_rate\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mPPI\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mOECD_CLI_index\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mCSI_index\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgdp_per_capita\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m ]\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Run the full VARMAX pipeline\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m model, results, forecast_orig = \u001b[43mrun_varmax_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_indicators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfinancial_indicators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exog_features\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Maximum number of exogenous features\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Number of Optuna trials for hyperparameter tuning\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Save model as .pkl\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_plots\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# Save plots to varmax_plots/\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Check results for each indicator\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m financial_indicators:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 175\u001b[39m, in \u001b[36mrun_varmax_pipeline\u001b[39m\u001b[34m(train_df, test_df, target_indicators, max_exog_features, n_trials, save_model, save_plots)\u001b[39m\n\u001b[32m    172\u001b[39m test_targets_stat.dropna(inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    173\u001b[39m test_exog_stat.dropna(inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m model, results = \u001b[43mfit_varmax_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_targets_stat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_targets_stat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_exog_stat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_exog_stat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# Invert differencing for original scale\u001b[39;00m\n\u001b[32m    178\u001b[39m last_train_values = train_targets.iloc[-\u001b[32m1\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 116\u001b[39m, in \u001b[36mfit_varmax_model\u001b[39m\u001b[34m(train_targets, test_targets, train_exog, test_exog, n_trials)\u001b[39m\n\u001b[32m    113\u001b[39m val_targets, val_exog = train_targets.iloc[-val_size:], train_exog.iloc[-val_size:]\n\u001b[32m    115\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmake_varmax_objective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_exog_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_exog\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m best_order = (study.best_params[\u001b[33m'\u001b[39m\u001b[33mp\u001b[39m\u001b[33m'\u001b[39m], study.best_params[\u001b[33m'\u001b[39m\u001b[33mq\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    118\u001b[39m best_trend = study.best_params[\u001b[33m'\u001b[39m\u001b[33mtrend\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:258\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    254\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    255\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    257\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 101\u001b[39m, in \u001b[36mmake_varmax_objective.<locals>.objective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     93\u001b[39m     model = VARMAX(\n\u001b[32m     94\u001b[39m         endog=train_targets,\n\u001b[32m     95\u001b[39m         exog=train_exog,\n\u001b[32m   (...)\u001b[39m\u001b[32m     99\u001b[39m         enforce_invertibility=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    100\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     fitted = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlbfgs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m     forecast = fitted.forecast(steps=\u001b[38;5;28mlen\u001b[39m(val_targets), exog=val_exog.values)\n\u001b[32m    103\u001b[39m     rmse_sum = \u001b[38;5;28msum\u001b[39m(np.sqrt(mean_squared_error(val_targets[col], forecast[:, i]))\n\u001b[32m    104\u001b[39m                    \u001b[38;5;28;01mfor\u001b[39;00m i, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(val_targets.columns))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/statsmodels/tsa/statespace/mlemodel.py:704\u001b[39m, in \u001b[36mMLEModel.fit\u001b[39m\u001b[34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[39m\n\u001b[32m    702\u001b[39m         flags[\u001b[33m'\u001b[39m\u001b[33mhessian_method\u001b[39m\u001b[33m'\u001b[39m] = optim_hessian\n\u001b[32m    703\u001b[39m     fargs = (flags,)\n\u001b[32m--> \u001b[39m\u001b[32m704\u001b[39m     mlefit = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mMLEModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mskip_hessian\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[38;5;66;03m# Just return the fitted parameters if requested\u001b[39;00m\n\u001b[32m    712\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_params:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/statsmodels/base/model.py:566\u001b[39m, in \u001b[36mLikelihoodModel.fit\u001b[39m\u001b[34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[39m\n\u001b[32m    563\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_t\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    565\u001b[39m optimizer = Optimizer()\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m xopt, retvals, optim_settings = \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mhessian\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mretall\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[38;5;66;03m# Restore cov_type, cov_kwds and use_t\u001b[39;00m\n\u001b[32m    576\u001b[39m optim_settings.update(kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/statsmodels/base/optimizer.py:242\u001b[39m, in \u001b[36mOptimizer._fit\u001b[39m\u001b[34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[39m\n\u001b[32m    239\u001b[39m     fit_funcs.update(extra_fit_funcs)\n\u001b[32m    241\u001b[39m func = fit_funcs[method]\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m xopt, retvals = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mretall\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhessian\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m optim_settings = {\u001b[33m'\u001b[39m\u001b[33moptimizer\u001b[39m\u001b[33m'\u001b[39m: method, \u001b[33m'\u001b[39m\u001b[33mstart_params\u001b[39m\u001b[33m'\u001b[39m: start_params,\n\u001b[32m    248\u001b[39m                   \u001b[33m'\u001b[39m\u001b[33mmaxiter\u001b[39m\u001b[33m'\u001b[39m: maxiter, \u001b[33m'\u001b[39m\u001b[33mfull_output\u001b[39m\u001b[33m'\u001b[39m: full_output,\n\u001b[32m    249\u001b[39m                   \u001b[33m'\u001b[39m\u001b[33mdisp\u001b[39m\u001b[33m'\u001b[39m: disp, \u001b[33m'\u001b[39m\u001b[33mfargs\u001b[39m\u001b[33m'\u001b[39m: fargs, \u001b[33m'\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m'\u001b[39m: callback,\n\u001b[32m    250\u001b[39m                   \u001b[33m'\u001b[39m\u001b[33mretall\u001b[39m\u001b[33m'\u001b[39m: retall, \u001b[33m\"\u001b[39m\u001b[33mextra_fit_funcs\u001b[39m\u001b[33m\"\u001b[39m: extra_fit_funcs}\n\u001b[32m    251\u001b[39m optim_settings.update(kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/statsmodels/base/optimizer.py:659\u001b[39m, in \u001b[36m_fit_lbfgs\u001b[39m\u001b[34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[39m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m approx_grad:\n\u001b[32m    657\u001b[39m     func = f\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m retvals = \u001b[43moptimize\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfmin_l_bfgs_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m full_output:\n\u001b[32m    665\u001b[39m     xopt, fopt, d = retvals\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/scipy/optimize/_lbfgsb_py.py:199\u001b[39m, in \u001b[36mfmin_l_bfgs_b\u001b[39m\u001b[34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[39m\n\u001b[32m    187\u001b[39m callback = _wrap_callback(callback)\n\u001b[32m    188\u001b[39m opts = {\u001b[33m'\u001b[39m\u001b[33mdisp\u001b[39m\u001b[33m'\u001b[39m: disp,\n\u001b[32m    189\u001b[39m         \u001b[33m'\u001b[39m\u001b[33miprint\u001b[39m\u001b[33m'\u001b[39m: iprint,\n\u001b[32m    190\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmaxcor\u001b[39m\u001b[33m'\u001b[39m: m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    196\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m'\u001b[39m: callback,\n\u001b[32m    197\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmaxls\u001b[39m\u001b[33m'\u001b[39m: maxls}\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m res = \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m                       \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m d = {\u001b[33m'\u001b[39m\u001b[33mgrad\u001b[39m\u001b[33m'\u001b[39m: res[\u001b[33m'\u001b[39m\u001b[33mjac\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    202\u001b[39m      \u001b[33m'\u001b[39m\u001b[33mtask\u001b[39m\u001b[33m'\u001b[39m: res[\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    203\u001b[39m      \u001b[33m'\u001b[39m\u001b[33mfuncalls\u001b[39m\u001b[33m'\u001b[39m: res[\u001b[33m'\u001b[39m\u001b[33mnfev\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    204\u001b[39m      \u001b[33m'\u001b[39m\u001b[33mnit\u001b[39m\u001b[33m'\u001b[39m: res[\u001b[33m'\u001b[39m\u001b[33mnit\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    205\u001b[39m      \u001b[33m'\u001b[39m\u001b[33mwarnflag\u001b[39m\u001b[33m'\u001b[39m: res[\u001b[33m'\u001b[39m\u001b[33mstatus\u001b[39m\u001b[33m'\u001b[39m]}\n\u001b[32m    206\u001b[39m f = res[\u001b[33m'\u001b[39m\u001b[33mfun\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/scipy/optimize/_lbfgsb_py.py:307\u001b[39m, in \u001b[36m_minimize_lbfgsb\u001b[39m\u001b[34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[39m\n\u001b[32m    304\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    305\u001b[39m         iprint = disp\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m sf = \u001b[43m_prepare_scalar_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m func_and_grad = sf.fun_and_grad\n\u001b[32m    313\u001b[39m fortran_int = _lbfgsb.types.intvar.dtype\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/scipy/optimize/_optimize.py:383\u001b[39m, in \u001b[36m_prepare_scalar_function\u001b[39m\u001b[34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[39m\n\u001b[32m    379\u001b[39m     bounds = (-np.inf, np.inf)\n\u001b[32m    381\u001b[39m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m sf = \u001b[43mScalarFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:177\u001b[39m, in \u001b[36mScalarFunction.__init__\u001b[39m\u001b[34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[39m\n\u001b[32m    173\u001b[39m         \u001b[38;5;28mself\u001b[39m.g = approx_derivative(fun_wrapped, \u001b[38;5;28mself\u001b[39m.x, f0=\u001b[38;5;28mself\u001b[39m.f,\n\u001b[32m    174\u001b[39m                                    **finite_diff_options)\n\u001b[32m    176\u001b[39m \u001b[38;5;28mself\u001b[39m._update_grad_impl = update_grad\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# Hessian Evaluation\u001b[39;00m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(hess):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:256\u001b[39m, in \u001b[36mScalarFunction._update_grad\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_update_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.g_updated:\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_grad_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    257\u001b[39m         \u001b[38;5;28mself\u001b[39m.g_updated = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:173\u001b[39m, in \u001b[36mScalarFunction.__init__.<locals>.update_grad\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;28mself\u001b[39m._update_fun()\n\u001b[32m    172\u001b[39m \u001b[38;5;28mself\u001b[39m.ngev += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m \u001b[38;5;28mself\u001b[39m.g = \u001b[43mapprox_derivative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                           \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfinite_diff_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/scipy/optimize/_numdiff.py:505\u001b[39m, in \u001b[36mapprox_derivative\u001b[39m\u001b[34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[39m\n\u001b[32m    502\u001b[39m     use_one_sided = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    504\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dense_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m                             \u001b[49m\u001b[43muse_one_sided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    508\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/scipy/optimize/_numdiff.py:576\u001b[39m, in \u001b[36m_dense_difference\u001b[39m\u001b[34m(fun, x0, f0, h, use_one_sided, method)\u001b[39m\n\u001b[32m    574\u001b[39m     x = x0 + h_vecs[i]\n\u001b[32m    575\u001b[39m     dx = x[i] - x0[i]  \u001b[38;5;66;03m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m     df = \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m - f0\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m'\u001b[39m\u001b[33m3-point\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m use_one_sided[i]:\n\u001b[32m    578\u001b[39m     x1 = x0 + h_vecs[i]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/scipy/optimize/_numdiff.py:456\u001b[39m, in \u001b[36mapprox_derivative.<locals>.fun_wrapped\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfun_wrapped\u001b[39m(x):\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     f = np.atleast_1d(\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    457\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m f.ndim > \u001b[32m1\u001b[39m:\n\u001b[32m    458\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m`fun` return value has \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    459\u001b[39m                            \u001b[33m\"\u001b[39m\u001b[33mmore than 1 dimension.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[39m, in \u001b[36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28mself\u001b[39m.nfev += \u001b[32m1\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m fx = \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isscalar(fx):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/statsmodels/base/model.py:534\u001b[39m, in \u001b[36mLikelihoodModel.fit.<locals>.f\u001b[39m\u001b[34m(params, *args)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mf\u001b[39m(params, *args):\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloglike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m / nobs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/statsmodels/tsa/statespace/mlemodel.py:939\u001b[39m, in \u001b[36mMLEModel.loglike\u001b[39m\u001b[34m(self, params, *args, **kwargs)\u001b[39m\n\u001b[32m    936\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m complex_step:\n\u001b[32m    937\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33minversion_method\u001b[39m\u001b[33m'\u001b[39m] = INVERT_UNIVARIATE | SOLVE_LU\n\u001b[32m--> \u001b[39m\u001b[32m939\u001b[39m loglike = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloglike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomplex_step\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomplex_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[38;5;66;03m# Koopman, Shephard, and Doornik recommend maximizing the average\u001b[39;00m\n\u001b[32m    942\u001b[39m \u001b[38;5;66;03m# likelihood to avoid scale issues, but the averaging is done\u001b[39;00m\n\u001b[32m    943\u001b[39m \u001b[38;5;66;03m# automatically in the base model `fit` method\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loglike\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/statsmodels/tsa/statespace/kalman_filter.py:1001\u001b[39m, in \u001b[36mKalmanFilter.loglike\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    985\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    986\u001b[39m \u001b[33;03mCalculate the loglikelihood associated with the statespace model.\u001b[39;00m\n\u001b[32m    987\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    997\u001b[39m \u001b[33;03m    The joint loglikelihood.\u001b[39;00m\n\u001b[32m    998\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    999\u001b[39m kwargs.setdefault(\u001b[33m'\u001b[39m\u001b[33mconserve_memory\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   1000\u001b[39m                   MEMORY_CONSERVE ^ MEMORY_NO_LIKELIHOOD)\n\u001b[32m-> \u001b[39m\u001b[32m1001\u001b[39m kfilter = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1002\u001b[39m loglikelihood_burn = kwargs.get(\u001b[33m'\u001b[39m\u001b[33mloglikelihood_burn\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   1003\u001b[39m                                 \u001b[38;5;28mself\u001b[39m.loglikelihood_burn)\n\u001b[32m   1004\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (kwargs[\u001b[33m'\u001b[39m\u001b[33mconserve_memory\u001b[39m\u001b[33m'\u001b[39m] & MEMORY_NO_LIKELIHOOD):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal learn dev/RecessionRadar/venv/lib/python3.12/site-packages/statsmodels/tsa/statespace/kalman_filter.py:924\u001b[39m, in \u001b[36mKalmanFilter._filter\u001b[39m\u001b[34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[39m\n\u001b[32m    921\u001b[39m \u001b[38;5;28mself\u001b[39m._initialize_state(prefix=prefix, complex_step=complex_step)\n\u001b[32m    923\u001b[39m \u001b[38;5;66;03m# Run the filter\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m924\u001b[39m \u001b[43mkfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m kfilter\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 2 List of all financial indicators you want to forecast\n",
    "financial_indicators = [\n",
    "    \"1_year_rate\", \"3_months_rate\", \"6_months_rate\", \"CPI\", \"INDPRO\",\n",
    "    \"10_year_rate\", \"share_price\", \"unemployment_rate\", \"PPI\",\n",
    "    \"OECD_CLI_index\", \"CSI_index\", \"gdp_per_capita\"\n",
    "]\n",
    "\n",
    "# Run the full VARMAX pipeline\n",
    "model, results, forecast_orig = run_varmax_pipeline(\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    target_indicators=financial_indicators,\n",
    "    max_exog_features=10,   # Maximum number of exogenous features\n",
    "    n_trials=20,            # Number of Optuna trials for hyperparameter tuning\n",
    "    save_model=True,        # Save model as .pkl\n",
    "    save_plots=True         # Save plots to varmax_plots/\n",
    ")\n",
    "\n",
    "# Check results for each indicator\n",
    "for ind in financial_indicators:\n",
    "    print(f\"{ind}: MAE={results[ind]['mae']:.4f}, RMSE={results[ind]['rmse']:.4f}, MAPE={results[ind]['mape']:.2f}%\")\n",
    "\n",
    "# Quick view of forecast\n",
    "print(forecast_orig.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
